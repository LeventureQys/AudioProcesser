# 4.5 DeepFilterNet：频域深度滤波

## 概述

DeepFilterNet是2022年德国Fraunhofer IIS的Hendrik Schröter等人搞出来的。这个方法在DNS Challenge 2022上拿了很好的成绩，而且计算量控制得不错，算是在性能和效率之间找到了一个比较好的平衡点。

名字里的"Deep Filtering"是它的核心思想：不是简单地给每个频点乘一个增益（传统掩码方法），而是预测一个时变的FIR滤波器，对相邻几帧做卷积。这样能利用时间上下文，顺便还能隐式地处理相位。

## 和RNNoise的区别

先说说DeepFilterNet和RNNoise的主要区别：

| | RNNoise | DeepFilterNet |
|---|---------|---------------|
| 核心思路 | 频带增益 | 深度滤波 |
| 相位处理 | 不处理 | 隐式处理 |
| 网络 | 纯GRU | 编码器+GRU+解码器 |
| 频率处理 | 32个ERB频带 | 双路径（ERB+线性） |
| 参数量 | ~100K | ~720K |
| PESQ | 2.54 | 2.89 |

简单说，DeepFilterNet用了更多参数换来了更好的效果，但计算量控制得还行，比DCCRN那些动辄几百万参数的方法轻量很多。

## ERB频带

DeepFilterNet也用了ERB频带分组，这个思路和RNNoise一样。

ERB（Equivalent Rectangular Bandwidth）是基于人耳听觉特性的频带划分。人耳在低频处分辨率高，高频处分辨率低，ERB就是按这个特性来划分的。

带宽公式：
$$B_{ERB}(f_c) = 24.7 \times (4.37 \times 10^{-3} f_c + 1)$$

具体数值：
- 100Hz处，带宽约35Hz
- 1000Hz处，带宽约132Hz
- 8000Hz处，带宽约894Hz

为什么用ERB不用Mel？在语音增强任务上，ERB效果略好一点。而且ERB的公式更简洁。

## 深度滤波是什么

这是DeepFilterNet最核心的创新。

**传统掩码方法**就是给每个时频点乘一个系数：
$$\hat{S}(k, t) = M(k, t) \cdot X(k, t)$$

**深度滤波**则是对相邻几帧做卷积：
$$\hat{S}(k, t) = \sum_{\tau=0}^{L-1} H(k, t, \tau) \cdot X(k, t-\tau)$$

$H$是网络预测的滤波器系数，$L$是滤波器长度（DeepFilterNet用的是5）。

直观理解：
```
传统掩码：当前帧 × 系数 = 输出
深度滤波：(当前帧×H0 + 前1帧×H1 + 前2帧×H2 + ...) = 输出
```

### 为什么这样能处理相位？

传统掩码只能改变幅度，相位没法动。但深度滤波用的是复数乘法，$H$和$X$都是复数，相乘的时候相位会叠加。

而且因为用了多帧信息，网络可以学到：语音在相邻帧之间高度相关，噪声相关性低。通过合适的滤波器系数，可以增强语音、抑制噪声，同时隐式地修正相位。

实际上DeepFilterNet的深度滤波还会在频率维度上做一点扩展，不只是时间维度。

## 双路径架构

DeepFilterNet用了两条路径：

```
输入频谱
    │
    ├──────────────────┐
    │                  │
    ▼                  ▼
ERB路径              DF路径
(32个ERB频带)        (96个线性频点)
(处理全频段)         (只处理0-5kHz)
(输出：增益)         (输出：滤波器系数)
    │                  │
    └──────────────────┘
            │
            ▼
        融合输出
```

**ERB路径**：处理全频段（0-24kHz），但分辨率粗（32个频带），输出实数增益。计算量小。

**DF路径**：只处理低频（0-5kHz，语音主要能量在这），分辨率高（96个频点），输出复数滤波器系数。能精细处理语音和相位。

为什么这么设计？

低频是语音的主体，需要精细处理，而且相位在低频更重要。高频主要是辅音和噪声，粗粒度处理就够了，没必要浪费计算量。

## 网络结构

整体结构：

```
输入
  ↓
编码器（几层卷积，逐步降采样）
  ↓
2层GRU（时序建模）
  ↓
  ├─→ ERB解码器 → 32维增益
  └─→ DF解码器 → 96×5×2维滤波器系数
```

### 编码器

几层Conv2D + GroupNorm + PReLU，逐步把频率维度降下来。

为什么用GroupNorm不用BatchNorm？BatchNorm依赖batch size，小batch效果不好。GroupNorm把通道分组，在组内归一化，不依赖batch size。

### GRU

2层GRU，每层256单元，单向（保证因果性）。

为什么只用2层？实验发现3层提升很小（不到0.05 PESQ），但计算量增加不少。够用就行。

### 解码器

**ERB解码器**很简单：一个全连接层，256→32，加Sigmoid输出0-1的增益。

**DF解码器**复杂一点：两层全连接，最后输出96×5×2维，reshape成96个频点、5个时间tap、实部虚部。

### 跳跃连接

编码器和解码器之间有跳跃连接，把高分辨率特征传过去。这个和U-Net的思路一样，帮助保留细节。

## 损失函数

DeepFilterNet用了多个损失：

$$\mathcal{L} = \lambda_1 \mathcal{L}_{spec} + \lambda_2 \mathcal{L}_{multi} + \lambda_3 \mathcal{L}_{alpha}$$

**频谱损失**：幅度L1 + 实部L1 + 虚部L1，同时优化幅度和相位。

**多分辨率STFT损失**：用不同FFT大小（512、1024、2048）算损失，捕获不同时频分辨率的信息。

**Alpha损失**：$\|||\hat{S}|^\alpha - |S|^\alpha\||_1$，$\alpha$取0.3左右。这个对低能量区域更敏感，帮助保留语音细节。

为什么不直接用MSE？MSE对高能量区域过度关注，低能量的细节容易被忽略。

## 计算量

DeepFilterNet有几个版本：

| 版本 | 参数量 | 特点 |
|------|--------|------|
| DeepFilterNet | ~2M | 原版，效果最好 |
| DeepFilterNet2 | ~720K | 轻量版，性能效率平衡好 |
| DeepFilterNet3 | ~420K | 超轻量，适合嵌入式 |

DeepFilterNet2的RTF在普通CPU上约0.15，比RNNoise（0.07）慢一倍，但比DCCRN（0.8）快很多。

延迟方面，帧长10ms，加上处理时间，总延迟大概10-20ms，满足实时要求。

## 性能

DNS Challenge 2022结果：

| 指标 | DeepFilterNet2 |
|------|----------------|
| PESQ | 2.89 |
| SI-SDR | 17.5 dB |
| DNSMOS | 3.82 |

和RNNoise对比：

| | RNNoise | DeepFilterNet2 | 提升 |
|---|---------|----------------|------|
| PESQ | 2.54 | 2.89 | +0.35 |
| SI-SDR | 12.1 dB | 17.5 dB | +5.4 dB |

在低信噪比下优势更明显，主要是因为能处理相位。

### 消融实验

一些有意思的发现：

- 去掉DF路径：PESQ掉0.17
- 去掉ERB路径：PESQ掉0.21
- 滤波器长度从5减到1（等价于掩码）：PESQ掉0.17
- ERB频带从32减到16：PESQ掉0.11

说明双路径设计和深度滤波都很重要。滤波器长度5是个比较好的选择，再长收益很小。

### 不同噪声

风噪、低频噪声这种，DeepFilterNet优势明显（DF路径擅长处理低频）。复杂的非平稳噪声（街道、咖啡厅）也比RNNoise好不少。

## 局限性

1. **计算量比RNNoise高**：参数量是RNNoise的7倍，对于极端资源受限的场景可能还是太重
2. **泛化能力**：对没见过的噪声类型，跨数据集会掉点
3. **超低延迟**：10ms以下的延迟要求比较难满足
4. **多说话人**：和RNNoise一样，只能处理单说话人

## 影响

DeepFilterNet的几个贡献：

1. **深度滤波**：证明了用时变滤波器比简单掩码效果好，而且能隐式处理相位
2. **双路径设计**：不同频段用不同策略，计算资源花在刀刃上
3. **多分辨率损失**：这个损失函数设计后来被很多工作采用

GTCRN等后续方法都借鉴了DeepFilterNet的一些思路。

另外DeepFilterNet也是完全开源的，还提供了ONNX导出和Rust实现，部署很方便。

## 和RNNoise的对比总结

| | RNNoise | DeepFilterNet |
|---|---------|---------------|
| 定位 | 极致轻量 | 性能效率平衡 |
| 相位 | 不处理 | 隐式处理 |
| 参数量 | 100K | 720K |
| PESQ | 2.54 | 2.89 |
| 适用场景 | 资源极度受限 | 一般实时应用 |

两个都是很好的方法，选哪个看具体场景。资源特别紧张就用RNNoise，有点余量就用DeepFilterNet。

对于学习语音增强来说，建议先看RNNoise（架构简单），再看DeepFilterNet（在RNNoise基础上的改进）。
