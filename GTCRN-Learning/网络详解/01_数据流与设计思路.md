# GTCRN 网络详解：数据流与设计思路

## 一、核心问题：语音降噪要做什么？

语音降噪的本质是一个"分离"问题：

```
带噪语音 = 纯净语音 + 噪声
    ↓
   网络
    ↓
估计的纯净语音
```

难点在于：噪声和语音在时域/频域高度混叠，网络需要学会"听"出哪些成分是人声，哪些是噪声。

## 二、为什么选择 U-Net 架构？

### 2.1 语音降噪的特殊性

```
输入频谱: (513频点, T帧)
           ↓
         网络
           ↓
输出频谱: (513频点, T帧)   ← 尺寸必须完全相同！
```

这是一个典型的 **输入输出同尺寸** 任务，不像分类（输出一个标签）或检测（输出框坐标）。

### 2.2 U-Net 的优势

```
         编码器                    解码器
    ┌─────────────┐           ┌─────────────┐
    │  高分辨率   │ ─────────→│  高分辨率   │
    │  219频点    │   skip1   │  219频点    │
    └──────┬──────┘           └──────▲──────┘
           │ 下采样                   │ 上采样
    ┌──────▼──────┐           ┌──────┴──────┐
    │  中分辨率   │ ─────────→│  中分辨率   │
    │  110频点    │   skip2   │  110频点    │
    └──────┬──────┘           └──────▲──────┘
           │ 下采样                   │ 上采样
    ┌──────▼──────┐           ┌──────┴──────┘
    │  低分辨率   │──→ DPGRNN │
    │   55频点    │           │
    └─────────────┘           │
```

**跳跃连接的作用**：下采样会丢失细节，跳跃连接把编码器的细节直接传给解码器，避免"细节丢失"。

类比：就像画画时先画轮廓（低分辨率），再填细节（跳跃连接提供高分辨率参考）。

## 三、整体数据流

### 3.1 V1/V2 版本（非实时）

```
                         数据流总览
┌─────────────────────────────────────────────────────────────────┐
│                                                                 │
│   原始音频                                                       │
│      │                                                          │
│      ▼                                                          │
│   ┌─────────┐                                                   │
│   │  STFT   │  时域 → 频域                                       │
│   └────┬────┘                                                   │
│        │ 复数频谱 (B, 513, T, 2)                                 │
│        ▼                                                        │
│   ┌─────────┐                                                   │
│   │ERB 压缩 │  513频点 → 219 ERB 频带                            │
│   └────┬────┘                                                   │
│        │ (B, 3, T, 219)  [幅度, 实部, 虚部]                       │
│        ▼                                                        │
│   ┌─────────────────────────────────────────────┐               │
│   │              U-Net 主体                       │               │
│   │  ┌─────────┐    ┌─────────┐    ┌─────────┐  │               │
│   │  │ Encoder │ →  │ DPGRNN  │ →  │ Decoder │  │               │
│   │  │ 下采样   │    │ 时频建模 │    │ 上采样   │  │               │
│   │  └─────────┘    └─────────┘    └─────────┘  │               │
│   └────┬────────────────────────────────────────┘               │
│        │ 复数掩码 (B, 2, T, 219)                                 │
│        ▼                                                        │
│   ┌─────────┐                                                   │
│   │ERB 还原 │  219 → 513                                        │
│   └────┬────┘                                                   │
│        │                                                        │
│        ▼                                                        │
│   ┌─────────┐                                                   │
│   │  掩码   │  spec × mask (复数乘法)                            │
│   │  应用   │                                                   │
│   └────┬────┘                                                   │
│        │ 增强频谱 (B, 513, T, 2)                                 │
│        ▼                                                        │
│   ┌─────────┐                                                   │
│   │ iSTFT  │  频域 → 时域                                       │
│   └────┬────┘                                                   │
│        │                                                        │
│        ▼                                                        │
│   降噪后音频                                                     │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

## 四、频域表示：为什么用 STFT + ERB？

### 4.1 STFT：时域到频域

```
时域波形                          频谱图
 ┌────────────────────┐          ┌────────────────────┐
 │ ∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿ │   STFT   │ ████░░░░░░░░░░░░░░ │ 高频
 │                    │ ──────→  │ ██████░░░░░░░░░░░░ │
 │ 一维时间序列        │          │ ████████████░░░░░░ │ 中频
 │                    │          │ ██████████████████ │ 低频
 └────────────────────┘          └────────────────────┘
                                   时间 →
```

**为什么要转频域？**
- 时域中语音和噪声混在一起，难以区分
- 频域中，语音主要集中在特定频段（100-8000Hz），容易识别

**STFT 参数选择**：
- n_fft = 1024 → 产生 513 个频点
- hop_length = 480 → 每帧 10ms（48kHz 采样率）
- 帧之间有 50% 重叠，确保连续性

### 4.2 ERB：模拟人耳听觉

**问题**：513 个频点是线性分布的，但人耳对频率的感知是对数的！

```
人耳频率感知特性：
┌──────────────────────────────────────────────────────────────┐
│                                                              │
│  低频 (100-1000Hz)        中频 (1-4kHz)      高频 (4-24kHz)   │
│  ████████████████          ████████          ████            │
│  对细微变化很敏感          语音核心区         分辨率下降      │
│  需要更多频点              需要保持           可以合并       │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

**ERB 变换的作用**：
```
线性频点 513 个                    ERB 频带 219 个
┌─────────────────────┐           ┌─────────────────────┐
│  低频 171 个频点    │  ──────→  │  低频 171 个频带    │  1:1 保留
├─────────────────────┤           ├─────────────────────┤
│  高频 342 个频点    │  ──────→  │  高频 48 个 ERB 带  │  约 7:1 压缩
└─────────────────────┘           └─────────────────────┘
    计算量大                           计算量小
    高频冗余                           感知对齐
```

**ERB 滤波器组的原理**：

```
频率 (Hz)
    ▲
24k │                    ┌─▲─┐
    │                  ┌─┘ │ └─┐
    │                ┌─┘   │   └─┐     每个三角形 = 一个 ERB 滤波器
    │              ┌─┘     │     └─┐   相邻滤波器有重叠
 8k ├─────────────┴───────┴───────┴─
    │ ││││││││││││││││││││            低频：每个频点单独保留
    │ ││││││││││││││││││││            （更密集的条纹）
    │ ││││││││││││││││││││
    └─┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴┴───────────→ 频点索引
      0                171         513
```

**为什么 ERB 是可逆的？**
- 变换矩阵 W: (342, 48) 把 342 个高频点映射到 48 个 ERB 带
- 逆变换用 W 的转置，虽然有一定信息损失，但在感知上可以接受

## 五、编码器：逐层提取特征

### 5.1 编码器结构

```
输入 (B, 3, T, 219)
      │
      │  [幅度, 实部, 虚部] 三个通道
      ▼
┌─────────────────┐
│   DSConv 1      │  3ch → 32ch, 频率下采样 2x
│   stride=(1,2)  │  219 → 110
└────────┬────────┘
         │ ──────────────────────────────────→ skip1
         ▼
┌─────────────────┐
│   DSConv 2      │  32ch → 32ch, 频率下采样 2x
│   stride=(1,2)  │  110 → 55
└────────┬────────┘
         │ ──────────────────────────────────→ skip2
         ▼
┌─────────────────┐
│  GTConvLite ×6  │  dilation: 1,2,4,8,4,2
│  残差连接       │  尺寸不变: (B, 32, T, 55)
└────────┬────────┘
         │ ──────────────────────────────────→ skip3~8
         ▼
┌─────────────────┐
│ SubbandAttention│  频带级注意力
└────────┬────────┘
         │
         ▼
输出 (B, 32, T, 55)
```

### 5.2 深度可分离卷积（DSConv）：省参数的下采样

**普通卷积 vs 深度可分离卷积**：

```
普通 3×3 卷积 (32in → 32out):
┌─────────────────────────────────────┐
│  每个输出通道需要 32×3×3 = 288 个权重  │
│  总参数: 32 × 288 = 9,216            │
└─────────────────────────────────────┘

深度可分离卷积:
┌─────────────────────────────────────┐
│  Step 1: 深度卷积 (Depthwise)        │
│  每个通道独立做 3×3 卷积             │
│  参数: 32 × 9 = 288                 │
│                                     │
│  Step 2: 逐点卷积 (Pointwise)        │
│  1×1 卷积混合通道                    │
│  参数: 32 × 32 = 1,024              │
│                                     │
│  总参数: 288 + 1,024 = 1,312        │
│  节省: 9,216 → 1,312 (约 1/7)        │
└─────────────────────────────────────┘
```

**DSConv 结构**：
```
输入 (B, C_in, T, F)
      │
      ▼
┌─────────────────┐
│  Depthwise      │  每通道独立卷积
│  Conv (1,3)     │  groups = C_in
│  stride=(1,2)   │  只在频率轴下采样
└────────┬────────┘
         ▼
┌─────────────────┐
│  Pointwise      │  混合通道信息
│  Conv (1,1)     │
└────────┬────────┘
         ▼
┌─────────────────┐
│  BatchNorm      │  稳定训练
└────────┬────────┘
         ▼
┌─────────────────┐
│  PReLU          │  非线性激活
└────────┬────────┘
         ▼
输出 (B, C_out, T, F/2)
```

**为什么 stride 只作用在频率轴？**
- 时间轴不下采样，保持时间分辨率
- 频率轴下采样，压缩特征维度
- 语音信号的时间结构比频率结构更重要

### 5.3 GTConvLite：扩大感受野的残差块

**问题**：小卷积核的感受野有限，无法捕捉长距离依赖。

**解决方案**：使用空洞卷积（Dilated Convolution）

```
普通 3×3 卷积 (dilation=1):        空洞 3×3 卷积 (dilation=2):
┌───┬───┬───┐                     ┌───┬───┬───┬───┬───┐
│ █ │ █ │ █ │                     │ █ │   │ █ │   │ █ │
├───┼───┼───┤   感受野: 3×3       ├───┼───┼───┼───┼───┤   感受野: 5×5
│ █ │ ● │ █ │                     │   │   │   │   │   │
├───┼───┼───┤                     ├───┼───┼───┼───┼───┤
│ █ │ █ │ █ │                     │ █ │   │ ● │   │ █ │
└───┴───┴───┘                     ├───┼───┼───┼───┼───┤
                                  │   │   │   │   │   │
                                  ├───┼───┼───┼───┼───┤
                                  │ █ │   │ █ │   │ █ │
                                  └───┴───┴───┴───┴───┘
  ● = 中心点, █ = 采样点            参数量不变，感受野扩大！
```

**GTConvLite 的 dilation 设计 [1,2,4,8,4,2]**：

```
时间轴感受野变化:

  Layer 1 (d=1):  ███              感受野 = 3 帧
  Layer 2 (d=2):  █ █ █            感受野 = 5 帧 (累积~7)
  Layer 3 (d=4):  █   █   █        感受野 = 9 帧 (累积~15)
  Layer 4 (d=8):  █       █       █   感受野 = 17 帧 (累积~31)
  Layer 5 (d=4):  █   █   █        开始收缩
  Layer 6 (d=2):  █ █ █            继续收缩

为什么先扩大后收缩？
─────────────────────────────────────────────────────────────
  纯粹递增 [1,2,4,8,16,32] 的问题:
  - "网格效应": 相邻像素可能完全没有信息交流
  - 例如 d=8 时，只看第 0,8,16 帧，中间的帧被跳过

  金字塔结构 [1,2,4,8,4,2] 的优势:
  - 收缩阶段填补了扩张阶段跳过的位置
  - 最终每个位置都有充分的信息覆盖
─────────────────────────────────────────────────────────────
```

**GTConvLite 完整结构**：

```
输入 x (B, C, T, F)
      │
      ├───────────────────────────┐
      │                           │ 残差连接
      ▼                           │
┌─────────────────┐               │
│  Depthwise      │               │
│  Conv 3×3       │               │
│  dilation=(d,1) │               │
└────────┬────────┘               │
         ▼                        │
┌─────────────────┐               │
│ Pointwise + BN  │               │
│ + PReLU         │               │
└────────┬────────┘               │
         ▼                        │
┌─────────────────┐               │
│    TRALite      │  时间注意力    │
└────────┬────────┘               │
         ▼                        │
┌─────────────────┐               │
│    SEBlock      │  通道注意力    │
└────────┬────────┘               │
         │                        │
         ▼                        │
      x + h ←─────────────────────┘
         │
         ▼
输出 (B, C, T, F)
```

### 5.4 TRALite：时间注意力机制

**设计思路**：不同时间帧的重要性不同，让网络自己学习哪些帧更重要。

```
输入 x (B, C, T, F)
      │
      ▼
┌─────────────────────────────────────────────────┐
│  Step 1: 计算每帧的能量                          │
│                                                 │
│  energy = mean(x², dim=F)   沿频率轴平均         │
│                                                 │
│  结果: (B, C, T) 每个通道每帧一个能量值          │
└─────────────────────────────────────────────────┘
      │
      ▼
┌─────────────────────────────────────────────────┐
│  Step 2: 时间轴卷积学习注意力                    │
│                                                 │
│  深度卷积 (kernel=5): 看前后各 2 帧              │
│  逐点卷积 (kernel=1): 混合通道                   │
│  Sigmoid: 输出 0~1 的权重                        │
│                                                 │
│  结果: (B, C, T, 1) 每帧一个注意力权重           │
└─────────────────────────────────────────────────┘
      │
      ▼
┌─────────────────────────────────────────────────┐
│  Step 3: 加权                                   │
│                                                 │
│  output = x * attention                         │
│                                                 │
│  能量高的帧（可能是语音起始/重音）获得更高权重    │
└─────────────────────────────────────────────────┘
```

### 5.5 SEBlock：通道注意力机制

**设计思路**：不同通道学到的特征重要性不同，让网络自己学习通道权重。

```
输入 x (B, C, T, F)
      │
      ▼
┌─────────────────────────────────────────────────┐
│  Step 1: 全局平均池化                            │
│                                                 │
│  squeeze = mean(x, dim=(T,F))                   │
│                                                 │
│  把每个通道压缩成一个数: (B, C, 1, 1)             │
└─────────────────────────────────────────────────┘
      │
      ▼
┌─────────────────────────────────────────────────┐
│  Step 2: 两层全连接学习权重                      │
│                                                 │
│  FC1: C → C/4  (压缩)                           │
│  ReLU                                           │
│  FC2: C/4 → C  (还原)                           │
│  Sigmoid: 输出 0~1 的权重                        │
│                                                 │
│  结果: (B, C, 1, 1) 每个通道一个权重             │
└─────────────────────────────────────────────────┘
      │
      ▼
┌─────────────────────────────────────────────────┐
│  Step 3: 通道加权                               │
│                                                 │
│  output = x * weights                           │
│                                                 │
│  有用的通道放大，无用的通道抑制                   │
└─────────────────────────────────────────────────┘
```

### 5.6 SubbandAttention：频带注意力

**设计思路**：不同频带对降噪的重要性不同。

```
输入 x (B, C, T, F)  F=55 个频带
      │
      ▼
┌─────────────────────────────────────────────────┐
│  计算每个频带的能量分布                          │
│                                                 │
│  energy = mean(x², dim=(C,T))  → (B, F)         │
│                                                 │
│  FC: F → F/4 → F + Sigmoid                      │
│                                                 │
│  输出频带权重: (B, 1, 1, F)                      │
└─────────────────────────────────────────────────┘
      │
      ▼
  output = x * weights

作用: 自动学习强化语音频带、抑制噪声频带
```

## 六、DPGRNN：双路径时序建模

### 6.1 为什么需要 RNN？

**问题**：卷积的感受野是有限的，即使用空洞卷积也只能看到局部。

语音信号的特点：
- 一个音节可能持续 100-200ms
- 上下文依赖可能跨越整个句子
- 需要"全局"视野来理解语音结构

**RNN 的优势**：理论上可以看到任意长的历史信息。

### 6.2 双路径设计

```
为什么要"双路径"？
─────────────────────────────────────────────────────────────
  语音频谱是二维的:
  - 时间轴: 音素如何随时间变化
  - 频率轴: 谐波结构、共振峰分布

  单一方向的 RNN 只能捕捉一个维度的依赖
  双路径分别处理两个维度，更充分地建模
─────────────────────────────────────────────────────────────
```

**DPGRNN 结构**：

```
输入 x (B, 32, T, 55)
      │
      │
      ▼
┌─────────────────────────────────────────────────────────────┐
│                    Intra-path (频率方向)                      │
│                                                             │
│   reshape: (B, 32, T, 55) → (B×T, 55, 32)                   │
│                                                             │
│   每个时间帧独立，沿 55 个频带跑双向 GRU                       │
│                                                             │
│   ┌──────────────────────────────────────────────┐          │
│   │  →→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→→  │          │
│   │  频带 0  1  2  3  4  ...  52 53 54         │          │
│   │  ←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←←  │          │
│   └──────────────────────────────────────────────┘          │
│                                                             │
│   捕捉: 谐波关系、共振峰结构、频带间相关性                      │
│                                                             │
│   reshape 回: (B, 32, T, 55)                                │
│   残差连接 + LayerNorm                                       │
└──────────────────────────────────┬──────────────────────────┘
                                   │
                                   ▼
┌─────────────────────────────────────────────────────────────┐
│                    Inter-path (时间方向)                      │
│                                                             │
│   reshape: (B, 32, T, 55) → (B×55, T, 32)                   │
│                                                             │
│   每个频带独立，沿 T 帧跑单向 GRU                              │
│                                                             │
│   ┌──────────────────────────────────────────────┐          │
│   │  →→→→→→→→→→→→→→→→→→→→→→→→→→→→→→              │          │
│   │  帧 0  1  2  3  4  ...  T-2 T-1             │          │
│   └──────────────────────────────────────────────┘          │
│                                                             │
│   捕捉: 音素转换、节奏模式、长时依赖                           │
│                                                             │
│   reshape 回: (B, 32, T, 55)                                │
│   残差连接 + LayerNorm                                       │
└──────────────────────────────────┬──────────────────────────┘
                                   │
                                   ▼
输出 (B, 32, T, 55)
```

### 6.3 为什么 Intra 双向、Inter 单向？

```
Intra (频率方向) - 双向:
─────────────────────────────────────────────────────────────
  频率轴不涉及"因果性"
  低频信息对理解高频有帮助，反之亦然
  双向可以充分利用上下文
─────────────────────────────────────────────────────────────

Inter (时间方向) - 单向:
─────────────────────────────────────────────────────────────
  为了支持实时处理，时间轴必须是因果的
  当前帧只能依赖过去的帧，不能"偷看"未来
  V3 版本完全依赖这个设计实现流式处理
─────────────────────────────────────────────────────────────
```

### 6.4 可学习残差缩放 α 和 β

```
传统残差: output = x + h

问题: 训练初期，h 可能很大或很杂乱，直接加上去会不稳定

改进: output = x + α * h

α 初始化为 0.5，让网络自己学习:
- α → 0: 忽略这一层的贡献
- α → 1: 完全信任这一层
- 0 < α < 1: 加权融合
```

## 七、解码器：逐层还原

### 7.1 解码器结构

```
输入 (B, 32, T, 55)
      │
      │ + skip8 (最后一个 GTConv 的输出)
      ▼
┌─────────────────┐
│  GTConvLite     │  dilation=2
│  (对称)         │
└────────┬────────┘
         │ + skip7
         ▼
┌─────────────────┐
│  GTConvLite     │  dilation=4
└────────┬────────┘
    ... (共 6 层，dilation: 2,4,8,4,2,1)
         │
         │ + skip2 (DSConv2 的输出)
         ▼
┌─────────────────┐
│  DSDeconv 1     │  上采样: 55 → 110
└────────┬────────┘
         │ + skip1 (DSConv1 的输出)
         ▼
┌─────────────────┐
│  DSDeconv 2     │  上采样: 110 → 219
│                 │  通道: 32 → 2 (实部/虚部)
└────────┬────────┘
         │
         ▼
输出掩码 (B, 2, T, 219)
```

### 7.2 DSDeconv：转置卷积上采样

```
DSDeconv 结构:
─────────────────────────────────────────────────────────────

输入 (B, C, T, F)
      │
      ▼
┌─────────────────┐
│  Depthwise      │  转置卷积
│  ConvTranspose  │  stride=(1,2) → 频率放大 2 倍
└────────┬────────┘
         ▼
┌─────────────────┐
│  Pointwise      │  调整通道数
│  Conv 1×1       │
└────────┬────────┘
         ▼
  BatchNorm + PReLU
         │
         ▼
输出 (B, C_out, T, F×2)
```

## 八、复数掩码（CRM）：联合处理幅度和相位

### 8.1 传统方法的问题

```
传统理想比值掩码 (IRM):
─────────────────────────────────────────────────────────────
  mask = |clean| / |noisy|        只处理幅度

  enhanced = mask × noisy_mag     相位用带噪信号的

  问题: 相位也被噪声污染了！相位误差会导致听感不自然
─────────────────────────────────────────────────────────────
```

### 8.2 复数掩码的优势

```
复数掩码 (CRM):
─────────────────────────────────────────────────────────────
  网络输出: mask_real, mask_imag  (复数掩码)

  带噪频谱: noisy = a + bi
  复数掩码: mask = c + di

  增强频谱 = noisy × mask  (复数乘法)
           = (a + bi)(c + di)
           = (ac - bd) + (ad + bc)i

  enhanced_real = a×c - b×d
  enhanced_imag = a×d + b×c

  优势: 同时修正幅度和相位，效果更好
─────────────────────────────────────────────────────────────
```

### 8.3 掩码应用流程

```
┌──────────────────────────────────────────────────────────┐
│  解码器输出 mask_erb (B, 2, T, 219)                       │
│          │                                               │
│          ▼                                               │
│     ERB 逆变换                                            │
│          │                                               │
│          ▼                                               │
│  mask_linear (B, 2, T, 513)                              │
│          │                                               │
│          │     带噪频谱 spec (B, 513, T, 2)               │
│          │          │                                    │
│          ▼          ▼                                    │
│     ┌──────────────────────┐                             │
│     │    复数乘法           │                             │
│     │                      │                             │
│     │  out_r = s_r×m_r     │                             │
│     │        - s_i×m_i     │                             │
│     │                      │                             │
│     │  out_i = s_r×m_i     │                             │
│     │        + s_i×m_r     │                             │
│     └──────────┬───────────┘                             │
│                │                                         │
│                ▼                                         │
│     增强频谱 (B, 513, T, 2)                               │
└──────────────────────────────────────────────────────────┘
```

## 九、V3 版本：因果化改造

### 9.1 实时处理的约束

```
非因果 (V1/V2):
─────────────────────────────────────────────────────────────
  处理第 t 帧时，可以看到整个序列 [0, 1, ..., t, ..., T-1]

  优势: 利用更多信息，效果更好
  劣势: 必须等整个音频录完才能处理
─────────────────────────────────────────────────────────────

因果 (V3):
─────────────────────────────────────────────────────────────
  处理第 t 帧时，只能看到 [0, 1, ..., t]

  优势: 来一帧处理一帧，实时输出
  劣势: 信息受限，效果略差
─────────────────────────────────────────────────────────────
```

### 9.2 需要改造的模块

```
┌──────────────────────────────────────────────────────────┐
│                因果化改造清单                              │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  1. 卷积的 padding 方式                                   │
│     ┌─────────────────────────────────────────────┐      │
│     │ 非因果: padding = (d, d)  对称              │      │
│     │                                             │      │
│     │   past ─ ● ─ future   看到前后各 d 帧       │      │
│     │                                             │      │
│     │ 因果:   padding = (2d, 0) 只 pad 左边       │      │
│     │                                             │      │
│     │   past ─ ●            只看到过去 2d 帧      │      │
│     └─────────────────────────────────────────────┘      │
│                                                          │
│  2. TRALite 的时间卷积                                    │
│     ┌─────────────────────────────────────────────┐      │
│     │ 非因果: padding = k//2  对称                │      │
│     │ 因果:   只 pad 左边 (k-1)                   │      │
│     └─────────────────────────────────────────────┘      │
│                                                          │
│  3. DPGRNN 的 inter-path                                 │
│     ┌─────────────────────────────────────────────┐      │
│     │ 已经是单向 GRU，天然因果，无需修改           │      │
│     └─────────────────────────────────────────────┘      │
│                                                          │
│  4. DPGRNN 的 intra-path                                 │
│     ┌─────────────────────────────────────────────┐      │
│     │ 双向 GRU，但是沿频率轴                       │      │
│     │ 频率不涉及时间因果，可以保持双向             │      │
│     └─────────────────────────────────────────────┘      │
│                                                          │
└──────────────────────────────────────────────────────────┘
```

### 9.3 因果卷积示意

```
非因果卷积 (kernel=3, dilation=2):
─────────────────────────────────────────────────────────────

  时间轴:   t-4  t-3  t-2  t-1   t   t+1  t+2  t+3  t+4
            │              │    │    │              │
            └──────────────┼────┼────┼──────────────┘
                           █    ●    █

  输出 t 依赖: t-2, t, t+2  (看到未来的 t+2)
─────────────────────────────────────────────────────────────

因果卷积 (kernel=3, dilation=2):
─────────────────────────────────────────────────────────────

  时间轴:   t-4  t-3  t-2  t-1   t   t+1  t+2  t+3  t+4
            │              │    │    │
            └──────────────┼────┼────┘
                           █    █    ●

  输出 t 依赖: t-4, t-2, t  (只看过去)

  实现: 输入左边 pad (k-1)×d = 4 个零，右边不 pad
─────────────────────────────────────────────────────────────
```

### 9.4 V3 额外的结构变化

```
┌──────────────────────────────────────────────────────────┐
│                    V1/V2 vs V3 对比                       │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  输入处理:                                                │
│  ─────────                                               │
│  V1/V2: [幅度, 实部, 虚部] → SFE_Lite → 3 通道            │
│  V3:    [实部, 虚部] → 1×1 Conv → 3 通道                  │
│         (去掉幅度输入，简化前处理)                         │
│                                                          │
│  GTConv kernel:                                          │
│  ───────────────                                         │
│  V1/V2: 3×3 卷积核                                       │
│  V3:    5×5 卷积核 (更大感受野补偿因果性损失)              │
│                                                          │
│  激活函数:                                                │
│  ─────────                                               │
│  V1/V2: PReLU (可学习斜率)                               │
│  V3:    SiLU (Swish, 更平滑)                             │
│                                                          │
│  BatchNorm 位置:                                         │
│  ─────────────                                           │
│  V1/V2: DW → PW → BN → Act                              │
│  V3:    DW → BN → Act → PW → BN → Act (更频繁的归一化)   │
│                                                          │
└──────────────────────────────────────────────────────────┘
```

### 9.5 流式推理需要维护的状态

```
┌──────────────────────────────────────────────────────────┐
│                   流式推理状态缓存                         │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  1. 因果卷积的历史帧缓存                                  │
│     ┌─────────────────────────────────────────────┐      │
│     │  每个因果卷积层需要缓存 (kernel-1)×dilation 帧│      │
│     │                                             │      │
│     │  GTConv (12层):                             │      │
│     │    dilation = [1,2,4,8,4,2, 2,4,8,4,2,1]   │      │
│     │    kernel = 5                               │      │
│     │    缓存帧数 = 4×dilation                    │      │
│     │                                             │      │
│     │  最大单层缓存: 4×8 = 32 帧                   │      │
│     └─────────────────────────────────────────────┘      │
│                                                          │
│  2. TRALite 的历史能量                                    │
│     ┌─────────────────────────────────────────────┐      │
│     │  每层缓存 kernel-1 = 4 帧的能量值            │      │
│     │  共 12 层 TRA                               │      │
│     └─────────────────────────────────────────────┘      │
│                                                          │
│  3. GRU 的 hidden state                                  │
│     ┌─────────────────────────────────────────────┐      │
│     │  Inter-GRU (单向):                          │      │
│     │    2 个 DPGRNN × 2 层 GRU                   │      │
│     │    hidden: (num_layers, B×F, hidden_size)   │      │
│     │                                             │      │
│     │  Intra-GRU: 不需要缓存 (每帧独立)            │      │
│     └─────────────────────────────────────────────┘      │
│                                                          │
│  4. Skip connection 缓存                                 │
│     ┌─────────────────────────────────────────────┐      │
│     │  编码器的 8 个输出需要传给解码器              │      │
│     │  流式时需要对齐时间戳                        │      │
│     └─────────────────────────────────────────────┘      │
│                                                          │
└──────────────────────────────────────────────────────────┘
```

## 十、三个版本对比

```
┌────────────────────────────────────────────────────────────────┐
│                        版本特性对比                              │
├─────────────┬──────────────┬──────────────┬───────────────────┤
│    特性      │     V1       │     V2       │        V3         │
├─────────────┼──────────────┼──────────────┼───────────────────┤
│  网络结构    │   基础版      │  与V1相同     │   因果化改造       │
├─────────────┼──────────────┼──────────────┼───────────────────┤
│  损失函数    │  标准 RI+Mag  │ 瞬态感知损失  │   标准 RI+Mag     │
├─────────────┼──────────────┼──────────────┼───────────────────┤
│  实时支持    │     否        │     否       │       是          │
├─────────────┼──────────────┼──────────────┼───────────────────┤
│  参数量      │    ~139K     │    ~139K     │      ~145K        │
├─────────────┼──────────────┼──────────────┼───────────────────┤
│  DNSMOS     │    3.15      │    3.15      │      ~2.98        │
├─────────────┼──────────────┼──────────────┼───────────────────┤
│  算法延迟    │  整段处理     │  整段处理     │    10ms/帧        │
├─────────────┼──────────────┼──────────────┼───────────────────┤
│  适用场景    │  离线处理     │ 突发噪音场景  │   实时通话/直播    │
│             │  播客后期     │ 办公室录音    │   嵌入式部署       │
└─────────────┴──────────────┴──────────────┴───────────────────┘
```

## 十一、设计思路总结

### 11.1 核心设计哲学

```
┌──────────────────────────────────────────────────────────┐
│  1. 感知对齐                                              │
│     - ERB 变换模拟人耳，低频精细高频粗糙                    │
│     - 计算资源投入到人耳敏感的地方                         │
│                                                          │
│  2. 参数效率                                              │
│     - 深度可分离卷积，参数量降到 1/7                       │
│     - 139K 参数实现不错的效果                             │
│                                                          │
│  3. 感受野扩展                                            │
│     - 空洞卷积金字塔 [1,2,4,8,4,2]                        │
│     - 先扩大后收缩，避免网格效应                           │
│                                                          │
│  4. 多尺度注意力                                          │
│     - TRALite: 时间维度                                  │
│     - SEBlock: 通道维度                                  │
│     - SubbandAttention: 频率维度                         │
│                                                          │
│  5. 双路径建模                                            │
│     - Intra: 频率依赖（谐波、共振峰）                      │
│     - Inter: 时间依赖（音素、节奏）                        │
│                                                          │
│  6. 复数域处理                                            │
│     - CRM 同时修正幅度和相位                              │
│     - 比只处理幅度效果更好                                │
│                                                          │
│  7. 因果性考虑                                            │
│     - V1/V2 的 inter-GRU 已经是单向                       │
│     - V3 只需改造卷积的 padding                           │
│     - 为实时场景预留扩展空间                              │
└──────────────────────────────────────────────────────────┘
```

### 11.2 选型建议

```
你应该使用哪个版本？
─────────────────────────────────────────────────────────────

  场景: 播客后期、视频配音、音乐录制
  推荐: V1
  原因: 质量优先，不需要实时

  场景: 办公室录音、会议录制
  推荐: V2
  原因: 键盘鼠标等突发噪音处理更好

  场景: 实时通话、视频直播、游戏语音
  推荐: V3
  原因: 必须低延迟

  场景: 嵌入式设备、边缘计算
  推荐: V3 + C 语言实现
  原因: 资源受限，需要流式处理

─────────────────────────────────────────────────────────────
```
