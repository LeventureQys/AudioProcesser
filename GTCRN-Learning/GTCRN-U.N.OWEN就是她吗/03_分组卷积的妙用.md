# 03. 分组卷积的妙用

GTCRN能在手机上跑起来，分组卷积功不可没。这个技巧把计算量砍掉了32倍。

## 标准卷积的问题

先看标准卷积的计算量。对于一个卷积层：
- 输入通道 $C_{in}$，输出通道 $C_{out}$
- 卷积核大小 $K \times K$
- 输出尺寸 $H \times W$

MACs（乘累加操作）数量：
$$MACs = H \times W \times C_{in} \times C_{out} \times K^2$$

GTCRN第一层如果用标准卷积：32输入通道、64输出通道、3×3卷积核，每帧的计算量是 $32 \times 64 \times 9 = 18432$ 次乘累加。参数量也是18432。

这还只是一层，整个网络加起来就很可观了。

## 分组卷积怎么省计算

分组卷积的思路很简单：把通道分成G组，每组独立做卷积，互不干扰。

$$MACs_{分组} = \frac{1}{G} \times MACs_{标准}$$

GTCRN用G=32，正好等于ERB频带数。每个频带独立处理，计算量直接除以32。

同样的第一层，分组卷积后：$18432 / 32 = 576$ 次乘累加。参数量也是576。

## 为什么G=32

这个数字不是随便选的。GTCRN的输入是32个ERB频带，每个频带代表一段频率范围。

关键观察：**相邻ERB频带之间的相关性其实没那么强**。低频的频带和高频的频带，处理的信息差别很大。让它们独立处理，信息损失不大，但计算量大幅减少。

消融实验的结果：

| 分组数G | PESQ | 参数量 |
|---------|------|-------|
| 1 (标准卷积) | 3.25 | 280K |
| 8 | 3.36 | 35K |
| 16 | 3.39 | 17.5K |
| **32** | **3.42** | **8.75K** |
| 64 | 3.40 | 4.38K |

G=32是最优点。再大性能反而下降，因为组内通道太少，表达能力不够了。

## 信息交互怎么办

分组卷积的代价是组间没有信息交互。GTCRN怎么解决这个问题？

**分层处理**：第一层用分组卷积做频带内处理，后面的层用标准卷积做跨频带融合。

```python
class GTCRNEncoder(nn.Module):
    def __init__(self):
        super().__init__()
        # 第一层：分组卷积，频带内处理
        self.conv1 = nn.Conv2d(32, 64, kernel_size=3, groups=32, padding=1)
        # 后续层：标准卷积，跨频带融合
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
```

这样既省了计算，又保证了信息能在频带间流动。

## 硬件友好

分组卷积对硬件也友好：

1. **内存访问局部化**：每组只访问自己的那部分数据，缓存命中率高
2. **天然并行**：各组可以在不同核心上同时计算
3. **小矩阵运算**：多个小矩阵乘法比一个大矩阵乘法更容易优化

在移动端CPU上，分组卷积的实际加速比往往比理论值还好。

## 实现细节

PyTorch里用groups参数就行：

```python
# 标准卷积
conv_standard = nn.Conv2d(32, 64, kernel_size=3, padding=1)
# 参数量: 32 * 64 * 9 = 18432

# 分组卷积
conv_grouped = nn.Conv2d(32, 64, kernel_size=3, padding=1, groups=32)
# 参数量: (32/32) * (64/32) * 9 * 32 = 576
```

注意输入输出通道数都要能被groups整除。
