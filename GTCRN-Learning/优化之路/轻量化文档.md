# GTCRN-Light v3 技术说明书


---

## 0. 扼要（Executive Summary）

GTCRN-Light v3（以下简称 **v3**）是在**原生 GTRCN** 基础上进行的**等价轻量化实现**：完整保留“**ERB→SFE→Encoder（频轴两次 /2）→DPGRNN（intra→inter）→Decoder（镜像+跳连）→ERB⁻¹→复域 CRM**”的**主干数据流与功能语义**，通过算子级设计收缩参数与 MACs，同时增强形状稳定性与工程可部署性。
核心收益：

* **结构等价**：无语义重构、无路径删减；对齐原版的时/频建模顺序与接口。
* **计算瘦身**：卷积 DW-Separable 化、RNN 低秩瓶颈、门控去 RNN 化、ERB 固定权重化。
* **工程稳态**：严格的频轴上/下采样闭环（33→65→129），对齐安全，易于导出与部署。

---

## 1. 设计目标与边界（Design Goals & Constraints）

* **不改变** GTRCN 的任务假设与编解码语义：复域 CRM、ERB 子带、频轴二次下采样、DPGRNN（先 intra 后 inter）、镜像解码与跳连。
* **降低参数与 MACs**，但**不牺牲** DPGRNN 的双路径长程/跨频建模。
* **形状稳定**：频轴整数对齐，杜绝奇偶差累积；跳连前天然同维。
* **部署友好**：避免难以量化/导出的算子（极小化状态化 RNN、减少不必要的线性层）。

---

## 2. 与原生 GTRCN 保持一致的“架构不变量”

1. **数据流**：
   `(B,F,T,2) → [|S|, Re, Im] → ERB(bm) → SFE → Encoder(freq /2 ×2) → DPGRNN(intra→inter) → Decoder → ERB(bs) → CRM × S(复域)`
2. **采样策略**：ERB 后 **F=129**；编码两次在**频轴** /2：129→65→33；解码反向：33→65→129（确保 33→65→129 的闭环）。
3. **时/频耦合**：瓶颈处严格遵循 **intra-(per time, across F) → inter-(per freq, across T)** 的双路径顺序。
4. **输出语义**：预测 **CRM（实/虚）** 并在**复域**与输入逐点相乘。

---

## 3. 轻量化的四大支柱（Pillars of Lightweighting）

### 3.1 卷积主干 DW-Separable 化 + 轻量 GT-ConvLite

* **动机**：将 2D 卷积的通道耦合与空间（T/F）卷积解耦，保留感受野与局部子带建模能力的同时，将参数与 MACs 近似按 **1/通道数** 降低。
* **做法**：

  * 编码/解码的下/上采样层：`Depthwise(1×3, stride=(1,2) on F) + Pointwise(1×1)`；
  * 语义卷积块（GT-Conv）改为 **GT-ConvLite**：`Depthwise dilated (3×3, dilation on T) + 1×1 + BN + PReLU`，外接轻量时域门控（见 3.2）。
* **保持**：与原 GT-Conv 的“扩大感受野 + 时域门控 + 残差融合”功能等价。

### 3.2 TRALite：将 TRA 的时域门控改为深度可分 1D 卷积

* **动机**：TRA 原本通过 RNN/Attention 对时域能量进行门控，参数与状态管理较重；我们以**通道独立**的 1D 深度卷积代替，再用 1×1 调谐与 Sigmoid 形成门控，**零状态**、**可量化**、**极小参数**。
* **做法**：`DW-1D(k=3) → PW-1D → Sigmoid`，作用在 `mean_F(|x|^2)` 的时域能量轨迹上，对特征 `(B,C,T,1)` 做逐时刻缩放。

### 3.3 DPGRNN 瓶颈化：C→r→C 的低秩投影（保持双路径、缩小隐藏维）

* **动机**：DPGRNN 是 GTRCN 的建模灵魂，但 RNN 的隐藏维是主要参数与 MACs 来源。
* **做法**：在 **intra** 与 **inter** 两条路径前统一做 `Linear(C→r)`，RNN 在 **r** 维运行，输出再投影回 `Linear(r*(1+bidir)→C)` / `Linear(r→C)`；默认取 `r≈0.75·C`（可调，最小下限 8）。
* **归一化策略**：两次残差后均在 `(B,T,F,C)` 上做 `LayerNorm(C)`，避免与频轴长度绑定，**规模可变更鲁棒**。
* **顺序保持**：`intra@F|t → inter@T|f` 与原版一致。

### 3.4 ERB 滤组固定化（Buffer 化）

* **动机**：ERB 三角滤组是**固定前端**，无需可训练。
* **做法**：将 `bm, bs` 的权重矩阵以 `register_buffer` 固定为 `W_bm ∈ R^{F_high×erb2}`, `W_bs ∈ R^{erb2×F_high}`（注意方向），在最后一维做 `matmul`/`einsum`。
* **收益**：**不计入参数量**，同时消除与线性层相关的导出差异与量化漂移。

> **补充支柱**：**通道基数与倍率（width_mult）策略**——将默认基数从 16→**12**，再用 `width_mult∈{0.5,0.75,1.0,...}` 连续缩放，形成“指标-算力”可调滑杆。

---

## 4. 模块级规格（Module-level Specs）

### 4.1 ERB 变换

* **输入/输出**：`bm: (B,3,T,F)→(B,3,T,129)`；`bs: (B,2,T,129)→(B,2,T,F)`
* **形式**：

  * `x_high_erb = x_high @ W_bm`（`W_bm: (F_high, erb2)`）
  * `x_high_lin = high    @ W_bs`（`W_bs: (erb2, F_high)`）
* **低频直通**：前 `erb_subband_1=65` bins 直连，后半经滤组映射。

### 4.2 SFE_Lite（子带上下文）

* **算子**：`Depthwise(1×3) on F` 聚合邻频局部；保持三通道不变。
* **动机**：在不展开通道的前提下获得子带上下文，减少 `Unfold` 带来的通道膨胀。

### 4.3 Encoder（频轴下采样 ×2）

* **Stem**：`DSConv(3→C, stride=(1,2))` : 129→65
* **Down2**：`DSConv(C→C, stride=(1,2))` : 65→33
* **GT-ConvLite 堆叠**：三层（dilation = 1, 2, 5），每层 `DW(3×3,dilated) + 1×1 + BN + PReLU + TRALite + Residual`。

### 4.4 DPGRNN_Bottleneck（瓶颈处）

* **Intra（沿 F）**：输入 `(B*T, F, C)` → `Linear(C→r)` → `GRU(r, r, bidir=on/off)` → `Linear(r*(1+bidir)→C)` → 残差到 `(B,C,T,F)`；`LayerNorm(C)`。
* **Inter（沿 T）**：输入 `(B*F, T, C)` → `Linear(C→r)` → `GRU(r, r, bidir=False)` → `Linear(r→C)` → 残差到 `(B,C,T,F)`；`LayerNorm(C)`。
* **备注**：`r`、`bidir`、`堆叠层数` 可开关（默认 1–2 层）。

### 4.5 Decoder（镜像上采样 ×2）

* **三层 GT-ConvLite**（dilation = 5, 2, 1），与编码对应层做**相加跳连**。
* **Two Ups**：`DSDeconv(stride=(1,2), k=(1,3), p=(0,1), output_padding=(0,0))`，保证 **33→65→129** 精确复原。
* **Head**：最后两通道输出复域掩膜 `tanh(M)`，在 `(B,2,T,F)` 上与输入复谱逐点相乘。

---

## 5. 复杂度与可调项（Complexity & Knobs）

### 5.1 理论复杂度走向

* **卷积**：`DW(k×k) + PW(1×1)` 取代 `Conv(k×k)`，参数与 MACs 近似按 `~C + C²` 替代 `~k²·C²`；
* **RNN**：由 `C` 维改为 `r` 维（`r≈α·C`，默认 α=0.75），参数约按 `α²` 缩减；如关闭 intra 双向，则再减半。
* **ERB**：由两层 Linear 参数（高维）→ **0 参数**（buffer），MACs 不变。
* **门控**：RNN→DW-1D + PW-1D，小幅常数级参数。

### 5.2 推荐配置（示例）

* **边缘/实时（约束更紧）**：`width_mult=0.75, r≈0.5C, use_two_dpgrnn=False, rnn_bidirectional=False`
* **平衡（默认）**：`width_mult=1.0, r≈0.75C, use_two_dpgrnn=True, rnn_bidirectional=True`
* **离线高质**：`width_mult=1.25, r≈C, use_two_dpgrnn=True, rnn_bidirectional=True`

> 实际 Para/MACs 请以你的 `tools/print_model_stats.py` 实测为准；v3 在“平衡/实时”配置下，相对原版 GTRCN 显著下降是可期的。

---

## 6. 训练与收敛建议（Training Notes）

* **损失**：`L = λ₁·L_RI + λ₂·L_mag + λ₃·L_CM`（复域 RI L1/L2、幅度 L1、相位一致性/余弦距离），可加 `SI-SDR`/波形 L1 的 teacher-guided 混合。
* **两阶段**：先固定 ERB 与卷积主干、只训 DPGRNN（加速收敛），后端到端微调。
* **稳定技巧**：`grad_clip=5`，`warmup 3–5 epochs`，`AdamW (1e-3)`，`SpecAug（T/F 轻度遮挡）`。
* **蒸馏（可选）**：以原 GTRCN 为 teacher，v3 为 student，做中间层 `L2`/注意力对齐，快速靠拢主指标。

---

## 7. 部署与工程实践（Deployment）

* **导出**：全卷积 + 标准 GRU + `tanh`/`BN`/`LN`，**易 TorchScript/ONNX**；ERB 为 buffer，无权重更新分支。
* **量化**：DW/PW 卷积天然友好；GRU 可半精度，或以 `qGRU`/LSTM 替换。
* **流式**：DPGRNN 的状态可**分块缓存**（time-chunk）；TRALite 无隐藏状态，流式无额外开销。
* **混合精度**：推荐 AMP/O2，注意 `LayerNorm`/`matmul` 的数值稳定性（加小 ε）。

---

## 8. 变更对照表（Before → After）

| 功能位点    | 原生 GTRCN          | v3 方案                          | 保留/变化        |
| ------- | ----------------- | ------------------------------ | ------------ |
| 频带映射    | ERB Linear（可训练实现） | **ERB Buffer**（固定三角滤组）         | 语义不变、参数归零    |
| SFE     | Unfold/通道展开       | **DW(1×3)** 子带聚合               | 功能等价、低开销     |
| 编码/解码卷积 | 标准/组卷积 + GT-Conv  | **DW-Separable + GT-ConvLite** | 结构语义等价，显著降参  |
| TRA     | RNN/Attention 门控  | **TRALite**（DW-1D + PW-1D）     | 时域门控语义等价     |
| DPGRNN  | C 维 RNN（×2）       | **C→r→C** 瓶颈 RNN（×1/×2 可选）     | 顺序与语义不变，低秩降参 |
| 频轴采样    | /2 ×2（129→65→33）  | **同**                          | 严格对齐         |
| 输出      | 复域 CRM            | **同**                          | —            |

---



## 9. 小结

v3 的全部改动**只在算子级与维度级**，确保“**看起来是 GTRCN、走起来是 GTRCN、输出也是 GTRCN**”；它将工程落地中最“重”的部分（卷积、门控、RNN）逐一低秩化与可分离化，同时通过 **ERB 固定化** 与**频轴闭环**提升稳定性与可部署性。
在**不牺牲主干语义**的前提下，v3 提供从 **实时-边缘**到**离线-高质**的一整套“**指标-算力可调**”配置，是对原生 GTRCN 的**面向生产环境**重制版。
